<!-- Generated by SpecStory -->

# Update script for image upload support (2025-09-22 03:29Z)

_**User (2025-09-22 01:21Z)**_

@https://docs.streamlit.io/develop/api-reference/chat/st.chat_input 
現在請更新 使得@litellm_multimodal_proxy_with_sdk.py 可以接受上傳圖片
以及以正確的格式傳給 LiteLLM completion

---

_**Assistant**_



---

## Todo List

- [-] Add image upload functionality with st.file_uploader
- [ ] Add image processing to convert uploaded images to base64 format
- [ ] Update message format to support multimodal content (text + image)
- [ ] Modify completion call to handle multimodal messages
- [ ] Update UI to display uploaded images in chat messages

---



---

<details><summary>Edit file: pages/litellm_multimodal_proxy_with_sdk.py</summary>

undefined

**Chunk 1**
Lines added: 3, lines removed: undefined

```diff
@@ -4,4 +4,7 @@
  from dotenv import load_dotenv, find_dotenv
  import mlflow.litellm
+ import base64
+ import cv2
+ import numpy as np
  
  load_dotenv(find_dotenv())
```

</details>

---



---

<details><summary>Edit file: pages/litellm_multimodal_proxy_with_sdk.py</summary>

undefined

**Chunk 1**
Lines added: 8, lines removed: undefined

```diff
@@ -25,4 +25,12 @@
  st.session_state["model"] = st.selectbox("Select Model", valid_models)
  
+ # Image upload functionality
+ st.subheader("Upload Image (Optional)")
+ uploaded_file = st.file_uploader("Choose an image file", type=['png', 'jpg', 'jpeg', 'gif', 'webp'])
+ 
+ # Display uploaded image if any
+ if uploaded_file is not None:
+     st.image(uploaded_file, caption="Uploaded Image", use_column_width=True)
+ 
  if "messages" not in st.session_state:
      st.session_state.messages = []
```

</details>

---



---

## Todo List

- [x] Add image upload functionality with st.file_uploader
- [-] Add image processing to convert uploaded images to base64 format
- [ ] Update message format to support multimodal content (text + image)
- [ ] Modify completion call to handle multimodal messages
- [ ] Update UI to display uploaded images in chat messages

---



---

<details><summary>Edit file: pages/litellm_multimodal_proxy_with_sdk.py</summary>

undefined

**Chunk 1**
Lines added: 27, lines removed: undefined

```diff
@@ -39,4 +39,31 @@
      st.session_state["session_id"] = str(uuid4())
  
+ def process_uploaded_image(uploaded_file):
+     """Process uploaded image and convert to base64 format for LiteLLM"""
+     if uploaded_file is None:
+         return None
+ 
+     # Convert uploaded file to OpenCV image format
+     file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
+     image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
+ 
+     if image is None:
+         st.error("Failed to decode the image file.")
+         return None
+ 
+     # Get image format from file extension
+     file_extension = uploaded_file.name.split('.')[-1].lower()
+     if file_extension == 'jpg':
+         file_extension = 'jpeg'
+ 
+     # Convert image to base64
+     success, buffer = cv2.imencode(f'.{file_extension}', image)
+     if not success:
+         st.error("Failed to encode the image.")
+         return None
+ 
+     encoded_image = base64.b64encode(buffer).decode('utf-8')
+     return f"data:image/{file_extension};base64,{encoded_image}"
+ 
  
  def clear_messages():
```

</details>

---



---

## Todo List

- [x] Add image upload functionality with st.file_uploader
- [x] Add image processing to convert uploaded images to base64 format
- [-] Update message format to support multimodal content (text + image)
- [ ] Modify completion call to handle multimodal messages
- [ ] Update UI to display uploaded images in chat messages

---



---

<details><summary>Edit file: pages/litellm_multimodal_proxy_with_sdk.py</summary>

undefined

**Chunk 1**
Lines added: 21, lines removed: 3

```diff
@@ -122,7 +122,25 @@
  # 輸入與串流輸出
  if prompt := st.chat_input("What is up?"):
-     st.session_state.messages.append({"role": "user", "content": prompt})
-     with st.chat_message("user"):
-         st.markdown(prompt)
+     # Process uploaded image if any
+     image_url = process_uploaded_image(uploaded_file) if uploaded_file else None
+ 
+     # Create message content based on whether there's an image
+     if image_url:
+         # Multimodal message with text and image
+         message_content = [
+             {"type": "text", "text": prompt},
+             {"type": "image_url", "image_url": {"url": image_url}}
+         ]
+         st.session_state.messages.append({"role": "user", "content": message_content})
+ 
+         # Display user message with image
+         with st.chat_message("user"):
+             st.markdown(prompt)
+             st.image(image_url, caption="Uploaded Image", use_column_width=True)
+     else:
+         # Text-only message
+         st.session_state.messages.append({"role": "user", "content": prompt})
+         with st.chat_message("user"):
+             st.markdown(prompt)
  
      with st.chat_message("assistant"):
```

</details>

---



---

## Todo List

- [x] Add image upload functionality with st.file_uploader
- [x] Add image processing to convert uploaded images to base64 format
- [x] Update message format to support multimodal content (text + image)
- [-] Modify completion call to handle multimodal messages
- [ ] Update UI to display uploaded images in chat messages

---



---

<details><summary>Edit file: pages/litellm_multimodal_proxy_with_sdk.py</summary>

undefined

**Chunk 1**
Lines added: 11, lines removed: 4

```diff
@@ -145,10 +145,17 @@
  
      with st.chat_message("assistant"):
+         # Process messages for completion call - handle multimodal content
+         processed_messages = []
+         for m in st.session_state.messages:
+             if isinstance(m["content"], list):
+                 # Multimodal message - keep as is
+                 processed_messages.append({"role": m["role"], "content": m["content"]})
+             else:
+                 # Text-only message
+                 processed_messages.append({"role": m["role"], "content": m["content"]})
+ 
          response = st.write_stream(
              stream_litellm(
-                 messages=[
-                     {"role": m["role"], "content": m["content"]}
-                     for m in st.session_state.messages
-                 ],
+                 messages=processed_messages,
                  model=st.session_state["model"],
                  user_id=st.session_state.get("username")
```

</details>

---



---

## Todo List

- [x] Add image upload functionality with st.file_uploader
- [x] Add image processing to convert uploaded images to base64 format
- [x] Update message format to support multimodal content (text + image)
- [x] Modify completion call to handle multimodal messages
- [-] Update UI to display uploaded images in chat messages

---



---

<details><summary>Edit file: pages/litellm_multimodal_proxy_with_sdk.py</summary>

undefined

**Chunk 1**
Lines added: 10, lines removed: 1

```diff
@@ -78,5 +78,14 @@
  for message in st.session_state.messages:
      with st.chat_message(message["role"]):
-         st.markdown(message["content"])
+         if isinstance(message["content"], list):
+             # Handle multimodal content (text + image)
+             for item in message["content"]:
+                 if item["type"] == "text":
+                     st.markdown(item["text"])
+                 elif item["type"] == "image_url":
+                     st.image(item["image_url"]["url"], use_column_width=True)
+         else:
+             # Handle text-only content
+             st.markdown(message["content"])
  
  
```

</details>

---



---

## Todo List

- [x] Add image upload functionality with st.file_uploader
- [x] Add image processing to convert uploaded images to base64 format
- [x] Update message format to support multimodal content (text + image)
- [x] Modify completion call to handle multimodal messages
- [x] Update UI to display uploaded images in chat messages

---



---



---



---

<details><summary>Edit file: pages/litellm_multimodal_proxy_with_sdk.py</summary>

undefined

**Chunk 1**
Lines added: 2, lines removed: 2

```diff
@@ -5,6 +5,6 @@
  import mlflow.litellm
  import base64
- import cv2
- import numpy as np
+ from PIL import Image
+ import io
  
  load_dotenv(find_dotenv())
```

</details>

---



---

<details><summary>Edit file: pages/litellm_multimodal_proxy_with_sdk.py</summary>

undefined

**Chunk 1**
Lines added: 20, lines removed: 18

```diff
@@ -44,26 +44,28 @@
          return None
  
-     # Convert uploaded file to OpenCV image format
-     file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
-     image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
- 
-     if image is None:
-         st.error("Failed to decode the image file.")
-         return None
+     try:
+         # Read the uploaded file as PIL Image
+         image = Image.open(uploaded_file)
  
-     # Get image format from file extension
-     file_extension = uploaded_file.name.split('.')[-1].lower()
-     if file_extension == 'jpg':
-         file_extension = 'jpeg'
+         # Get image format from file extension
+         file_extension = uploaded_file.name.split('.')[-1].lower()
+         if file_extension == 'jpg':
+             file_extension = 'jpeg'
  
-     # Convert image to base64
-     success, buffer = cv2.imencode(f'.{file_extension}', image)
-     if not success:
-         st.error("Failed to encode the image.")
+         # Convert image to RGB if it's not already
+         if image.mode != 'RGB':
+             image = image.convert('RGB')
+ 
+         # Convert image to base64
+         buffer = io.BytesIO()
+         image.save(buffer, format=file_extension.upper())
+         encoded_image = base64.b64encode(buffer.getvalue()).decode('utf-8')
+ 
+         return f"data:image/{file_extension};base64,{encoded_image}"
+ 
+     except Exception as e:
+         st.error(f"Failed to process the image: {str(e)}")
          return None
  
-     encoded_image = base64.b64encode(buffer).decode('utf-8')
-     return f"data:image/{file_extension};base64,{encoded_image}"
- 
  
  def clear_messages():
```

</details>

---



---



---



---

Read file: undefined

---



---

Perfect! I've successfully updated `litellm_multimodal_proxy_with_sdk.py` to support image uploads and pass them to LiteLLM completion in the correct format. Here's a summary of the changes I made:

## ✅ Completed Updates

1. **Added Image Upload Functionality**
   - Added `st.file_uploader` to accept image files (PNG, JPG, JPEG, GIF, WebP)
   - Added image preview display

2. **Added Image Processing**
   - Created `process_uploaded_image()` function using PIL (Pillow) library
   - Converts uploaded images to base64 format for LiteLLM compatibility
   - Handles different image formats and converts them properly

3. **Updated Message Format**
   - Modified message creation to support multimodal content (text + image)
   - When an image is uploaded, creates a message with both text and image content
   - Maintains backward compatibility with text-only messages

4. **Updated Completion Call**
   - Modified the completion call to properly handle multimodal messages
   - Added message processing to distinguish between text-only and multimodal content

5. **Updated UI Display**
   - Updated chat history display to show both text and images
   - Properly renders multimodal messages in the conversation

## Key Features

- **Seamless Integration**: The app now accepts both text and image inputs
- **Proper Format**: Images are converted to base64 data URLs compatible with LiteLLM
- **Chat History**: All messages (including images) are properly stored and displayed
- **Error Handling**: Includes proper error handling for image processing failures
- **Clean UI**: Maintains the original chat interface with added image upload capability

The updated application now supports multimodal conversations where users can upload images along with their text prompts, and these will be properly processed and sent to the LiteLLM completion API for analysis by vision-capable models like GPT-4 Vision or Gemini Pro Vision.

---

