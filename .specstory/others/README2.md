
## ğŸš€ å¿«é€Ÿé–‹å§‹ (Docker Compose)

### ä¸€éµå•Ÿå‹•æ‰€æœ‰æœå‹™

```bash
# 1. å…‹éš†é …ç›®
git clone <your-repo-url>
cd Streamlit-LiteLLM-MLFlow

# 2. è¨­ç½®ç’°å¢ƒè®Šæ•¸
cp environment.example .env
# ç·¨è¼¯ .env æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„ API é‡‘é‘°

# 3. å•Ÿå‹•æ‰€æœ‰æœå‹™
./start.sh

# åœæ­¢æ‰€æœ‰æœå‹™
./stop.sh
```

### æœå‹™åœ°å€

å•Ÿå‹•å¾Œæ‚¨å¯ä»¥è¨ªå•ï¼š
- **Streamlit æ‡‰ç”¨**: http://localhost:8501
- **LiteLLM Proxy**: http://localhost:4000
- **MLFlow UI**: http://localhost:5000

### æ‰‹å‹•å•Ÿå‹• (å¯é¸)

```bash
# ä½¿ç”¨ Docker Compose
docker-compose up --build

# æˆ–ä½¿ç”¨å–®å€‹æœå‹™
docker-compose up streamlit
docker-compose up litellm
docker-compose up mlflow
```

## ğŸ“ ç’°å¢ƒè®Šæ•¸è¨­ç½®

è¤‡è£½ `environment.example` ç‚º `.env` ä¸¦å¡«å…¥ä»¥ä¸‹è®Šæ•¸ï¼š

```bash
# AWS Credentials for Bedrock
AWS_ACCESS_KEY_ID=your_aws_access_key_id
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
AWS_REGION_NAME=us-east-1

# OpenAI API Key
OPENAI_API_KEY=sk-your-openai-api-key

# Gemini API Key
GEMINI_API_KEY=your-gemini-api-key
```

## ğŸ”§ é–‹ç™¼ç’°å¢ƒè¨­ç½®

### å‚³çµ±æ–¹å¼ (ä¸ä½¿ç”¨ Docker)

```bash
uv sync --all-groups
uv run streamlit run main.py
mlflow ui --backend-store-uri sqlite:///mlflow.db
```

```bash
uv run litellm --config ./litellm_config.yaml

# https://docs.litellm.ai/docs/proxy/docker_quick_start#22-make-call
curl -X POST 'http://localhost:4000/chat/completions' \
-H 'Content-Type: application/json' \
-H 'Authorization: Bearer sk-1234' \
-d '{
    "model": "bedrock-nova-pro",
    "messages": [
      {
        "role": "system",
        "content": "You are an LLM named gpt-4o"
      },
      {
        "role": "user",
        "content": "what is your name?"
      }
    ],
    "litellm_metadata": {
      "tags": [
        "mlflow.trace.user:user_42",
        "mlflow.trace.session:sess_2025-09-22_A"
      ]
    }
}'

# https://docs.litellm.ai/docs/proxy/model_management#usage
curl -X GET "http://localhost:4000/model/info" \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer sk-1234'
```
